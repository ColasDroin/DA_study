{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import seaborn as sns\n",
    "import xtrack as xt\n",
    "import xpart as xp\n",
    "import time\n",
    "from rich.progress import Progress\n",
    "from rich.progress import (\n",
    "    Progress,\n",
    "    BarColumn,\n",
    "    TextColumn,\n",
    "    TimeElapsedColumn,\n",
    "    SpinnerColumn,\n",
    "    TimeRemainingColumn,\n",
    ")\n",
    "\n",
    "# Backend for footprint analysis\n",
    "import backend_footprint_analysis.InteractionPoint as inp\n",
    "import backend_footprint_analysis.Detuning as dtune\n",
    "import backend_footprint_analysis.Footprint as fp\n",
    "import backend_footprint_analysis.BeamPhysics as BP\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "# Improve style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%config InlineBackend.figure_format='retina'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return twiss and survey from a given madx folder\n",
    "def return_twisse_and_survey(path, b2=False):\n",
    "    with open(path) as fid:\n",
    "        dd = json.load(fid)\n",
    "    line = xt.Line.from_dict(dd)\n",
    "    line.build_tracker()\n",
    "    p_co = xp.Particles.from_dict(dd[\"particle_on_tracker_co\"])\n",
    "    pd_sv = line.survey(reverse=b2).to_pandas()\n",
    "    pd_tw = line.twiss(particle_co_guess=p_co, reverse=b2).to_pandas()\n",
    "    return pd_tw, pd_sv\n",
    "\n",
    "\n",
    "def correct_dataframe(twiss_b1, survey_b1, twiss_b2, survey_b2):\n",
    "    # Correct indices\n",
    "    twiss_b1.index = twiss_b1.name\n",
    "    twiss_b2.index = twiss_b2.name\n",
    "    survey_b1.index = survey_b1.name\n",
    "    survey_b2.index = survey_b2.name\n",
    "\n",
    "    # # Correct column names\n",
    "    survey_b1.columns = [\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"z\",\n",
    "        \"theta\",\n",
    "        \"phi\",\n",
    "        \"psi\",\n",
    "        \"name\",\n",
    "        \"s\",\n",
    "        \"drift_length\",\n",
    "        \"angle\",\n",
    "        \"tilt\",\n",
    "        \"element0\",\n",
    "    ]\n",
    "    survey_b2.columns = [\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"z\",\n",
    "        \"theta\",\n",
    "        \"phi\",\n",
    "        \"psi\",\n",
    "        \"name\",\n",
    "        \"s\",\n",
    "        \"drift_length\",\n",
    "        \"angle\",\n",
    "        \"tilt\",\n",
    "    ]\n",
    "\n",
    "    return twiss_b1, survey_b1, twiss_b2, survey_b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading line from dict.           \n",
      "generating ./2967d3cd915f418683e97f40c0b24fcb.c\n",
      "the current directory is '/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2967d3cd915f418683e97f40c0b24fcb.c:6606: warning: \"_GNU_SOURCE\" redefined\n",
      " 6606 | #  define _GNU_SOURCE // enable GNU libc NAN extension if possible\n",
      "      | \n",
      "In file included from 2967d3cd915f418683e97f40c0b24fcb.c:50:\n",
      "/afs/cern.ch/work/c/cdroin/private/DA_study/miniconda/include/python3.10/pyconfig.h:1621: note: this is the location of the previous definition\n",
      " 1621 | #define _GNU_SOURCE 1\n",
      "      | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading line from dict.           \n",
      "generating ./e054270b22e643c2897b836dbe108ca3.c\n",
      "the current directory is '/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e054270b22e643c2897b836dbe108ca3.c:6606: warning: \"_GNU_SOURCE\" redefined\n",
      " 6606 | #  define _GNU_SOURCE // enable GNU libc NAN extension if possible\n",
      "      | \n",
      "In file included from e054270b22e643c2897b836dbe108ca3.c:50:\n",
      "/afs/cern.ch/work/c/cdroin/private/DA_study/miniconda/include/python3.10/pyconfig.h:1621: note: this is the location of the previous definition\n",
      " 1621 | #define _GNU_SOURCE 1\n",
      "      | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading line from dict.           \n",
      "generating ./f0ee455229c64c75b361753f48b09203.c\n",
      "the current directory is '/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f0ee455229c64c75b361753f48b09203.c:6606: warning: \"_GNU_SOURCE\" redefined\n",
      " 6606 | #  define _GNU_SOURCE // enable GNU libc NAN extension if possible\n",
      "      | \n",
      "In file included from f0ee455229c64c75b361753f48b09203.c:50:\n",
      "/afs/cern.ch/work/c/cdroin/private/DA_study/miniconda/include/python3.10/pyconfig.h:1621: note: this is the location of the previous definition\n",
      " 1621 | #define _GNU_SOURCE 1\n",
      "      | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading line from dict.           \n",
      "generating ./99001fb6450e4ea98e8435eda65fe2c6.c\n",
      "the current directory is '/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99001fb6450e4ea98e8435eda65fe2c6.c:6606: warning: \"_GNU_SOURCE\" redefined\n",
      " 6606 | #  define _GNU_SOURCE // enable GNU libc NAN extension if possible\n",
      "      | \n",
      "In file included from 99001fb6450e4ea98e8435eda65fe2c6.c:50:\n",
      "/afs/cern.ch/work/c/cdroin/private/DA_study/miniconda/include/python3.10/pyconfig.h:1621: note: this is the location of the previous definition\n",
      " 1621 | #define _GNU_SOURCE 1\n",
      "      | \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "l_arr = []\n",
    "l_b = [\n",
    "    1963,\n",
    "    2116,\n",
    "]  # 1963, 2116]\n",
    "l_bb = [\n",
    "    True,\n",
    "    True,\n",
    "]  # False, False]\n",
    "for idx_b1, idx_b2 in [\n",
    "    [\"000\", \"002\"],\n",
    "    [\"001\", \"003\"],\n",
    "]:  # [\"004\", \"006\"], [\"005\", \"007\"]]:\n",
    "    twiss_b1, survey_b1 = return_twisse_and_survey(\n",
    "        \"../opt_flathv_75_1500_withBB_chroma15_footprint/madx_\"\n",
    "        + idx_b1\n",
    "        + \"/xsuite_lines/line_bb_for_tracking.json\",\n",
    "        b2=False,\n",
    "    )\n",
    "    twiss_b2, survey_b2 = return_twisse_and_survey(\n",
    "        \"../opt_flathv_75_1500_withBB_chroma15_footprint/madx_\"\n",
    "        + idx_b2\n",
    "        + \"/xsuite_lines/line_bb_for_tracking.json\",\n",
    "        b2=True,\n",
    "    )\n",
    "    twiss_b1, survey_b1, twiss_b2, survey_b2 = correct_dataframe(\n",
    "        twiss_b1, survey_b1, twiss_b2, survey_b2\n",
    "    )\n",
    "    l_arr.append((twiss_b1, survey_b1, twiss_b2, survey_b2))\n",
    "\n",
    "# Importing twiss and survey\n",
    "# twiss_b1_original  = pd.read_pickle('data/lhcb1_opticsfile30_twiss.pkl')\n",
    "# survey_b1_original= pd.read_pickle('data/lhcb1_opticsfile30_survey.pkl')\n",
    "\n",
    "# twiss_b2_original  = pd.read_pickle('data/lhcb2_opticsfile30_twiss.pkl')\n",
    "# survey_b2_original = pd.read_pickle('data/lhcb2_opticsfile30_survey.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_twiss_and_survey(twiss_b1, survey_b1, twiss_b2, survey_b2, b, bb):\n",
    "    try:\n",
    "        # Edit df to look like original\n",
    "        twiss_b2_cleaned = twiss_b2.drop(\"_end_point\")\n",
    "        twiss_b2_cleaned.loc[\"ip3\"], twiss_b2_cleaned.loc[\"lhcb2ip3_p_\"] = (\n",
    "            twiss_b2_cleaned.loc[\"lhcb2ip3_p_\"].copy(),\n",
    "            twiss_b2_cleaned.loc[\"ip3\"].copy(),\n",
    "        )\n",
    "        twiss_b2_cleaned.index = twiss_b2_cleaned.name\n",
    "        s_ip3 = twiss_b2_cleaned.loc[\"ip3\"].s\n",
    "        s_lhcb2ip3_p_ = twiss_b2_cleaned.loc[\"lhcb2ip3_p_\"].s\n",
    "        twiss_b2_cleaned.loc[\"ip3\", \"s\"] = s_lhcb2ip3_p_\n",
    "        twiss_b2_cleaned.loc[\"lhcb2ip3_p_\", \"s\"] = s_ip3\n",
    "        twiss_b2 = twiss_b2_cleaned\n",
    "\n",
    "        survey_b2_cleaned = survey_b2.drop(\"_end_point\")\n",
    "        survey_b2_cleaned.loc[\"ip3\"], survey_b2_cleaned.loc[\"lhcb2ip3_p_\"] = (\n",
    "            survey_b2_cleaned.loc[\"lhcb2ip3_p_\"].copy(),\n",
    "            survey_b2_cleaned.loc[\"ip3\"].copy(),\n",
    "        )\n",
    "        survey_b2_cleaned.index = survey_b2_cleaned.name\n",
    "        s_ip3 = survey_b2_cleaned.loc[\"ip3\"].s\n",
    "        s_lhcb2ip3_p_ = survey_b2_cleaned.loc[\"lhcb2ip3_p_\"].s\n",
    "        survey_b2_cleaned.loc[\"ip3\", \"s\"] = s_lhcb2ip3_p_\n",
    "        survey_b2_cleaned.loc[\"lhcb2ip3_p_\", \"s\"] = s_ip3\n",
    "        survey_b2 = survey_b2_cleaned\n",
    "\n",
    "        twiss_b1 = twiss_b1.drop(\"_end_point\")\n",
    "        survey_b1 = survey_b1.drop(\"_end_point\")\n",
    "    except:\n",
    "        print(\"Bug in cleaning\", b, bb)\n",
    "    return twiss_b1, survey_b1, twiss_b2, survey_b2\n",
    "\n",
    "\n",
    "# Clean data\n",
    "l_arr_cleaned = []\n",
    "for (twiss_b1, survey_b1, twiss_b2, survey_b2), b, bb in zip(l_arr, l_b, l_bb):\n",
    "    l_arr_cleaned.append(clean_twiss_and_survey(twiss_b1, survey_b1, twiss_b2, survey_b2, b, bb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7370c6dc9c58442895a25694fbd41dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:60: \n",
       "RuntimeWarning: overflow encountered in double_scalars\n",
       "  return sign*np.exp(-X-2*Y)/2/np.pi * integratedFactor\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:60: \n",
       "RuntimeWarning: overflow encountered in double_scalars\n",
       "  return sign*np.exp(-X-2*Y)/2/np.pi * integratedFactor\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:85: \n",
       "RuntimeWarning: invalid value encountered in double_scalars\n",
       "  return np.exp(-t/2*(azbar-dzbar)**2)*Bess2D(X,Y,0)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:85: \n",
       "RuntimeWarning: invalid value encountered in double_scalars\n",
       "  return np.exp(-t/2*(azbar-dzbar)**2)*Bess2D(X,Y,0)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:107: \n",
       "RuntimeWarning: overflow encountered in exp\n",
       "  return etaz*np.exp(-t/2*(azbar-dzbar)**2)*(np.exp(-X-2*Y)/2/np.pi)*integratedFactor\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:107: \n",
       "RuntimeWarning: overflow encountered in exp\n",
       "  return etaz*np.exp(-t/2*(azbar-dzbar)**2)*(np.exp(-X-2*Y)/2/np.pi)*integratedFactor\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:107: \n",
       "RuntimeWarning: invalid value encountered in double_scalars\n",
       "  return etaz*np.exp(-t/2*(azbar-dzbar)**2)*(np.exp(-X-2*Y)/2/np.pi)*integratedFactor\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:107: \n",
       "RuntimeWarning: invalid value encountered in double_scalars\n",
       "  return etaz*np.exp(-t/2*(azbar-dzbar)**2)*(np.exp(-X-2*Y)/2/np.pi)*integratedFactor\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:136: \n",
       "IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
       "  the requested tolerance from being achieved.  The error may be \n",
       "  underestimated.\n",
       "  return integrate.quad(lambda t: dC00dx_generating(t,ax,ay,r,dx_n,dy_n,method), 0, 1)[0]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:136: \n",
       "IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
       "  the requested tolerance from being achieved.  The error may be \n",
       "  underestimated.\n",
       "  return integrate.quad(lambda t: dC00dx_generating(t,ax,ay,r,dx_n,dy_n,method), 0, 1)[0]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:60: \n",
       "RuntimeWarning: overflow encountered in exp\n",
       "  return sign*np.exp(-X-2*Y)/2/np.pi * integratedFactor\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:60: \n",
       "RuntimeWarning: overflow encountered in exp\n",
       "  return sign*np.exp(-X-2*Y)/2/np.pi * integratedFactor\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:136: \n",
       "IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
       "  If increasing the limit yields no improvement it is advised to analyze \n",
       "  the integrand in order to determine the difficulties.  If the position of a \n",
       "  local difficulty can be determined (singularity, discontinuity) one will \n",
       "  probably gain from splitting up the interval and calling the integrator \n",
       "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
       "  return integrate.quad(lambda t: dC00dx_generating(t,ax,ay,r,dx_n,dy_n,method), 0, 1)[0]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:136: \n",
       "IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
       "  If increasing the limit yields no improvement it is advised to analyze \n",
       "  the integrand in order to determine the difficulties.  If the position of a \n",
       "  local difficulty can be determined (singularity, discontinuity) one will \n",
       "  probably gain from splitting up the interval and calling the integrator \n",
       "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
       "  return integrate.quad(lambda t: dC00dx_generating(t,ax,ay,r,dx_n,dy_n,method), 0, 1)[0]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:140: \n",
       "IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
       "  If increasing the limit yields no improvement it is advised to analyze \n",
       "  the integrand in order to determine the difficulties.  If the position of a \n",
       "  local difficulty can be determined (singularity, discontinuity) one will \n",
       "  probably gain from splitting up the interval and calling the integrator \n",
       "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
       "  return integrate.quad(lambda t: dC00dy_generating(t,ax,ay,r,dx_n,dy_n,method), 0, 1)[0]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:140: \n",
       "IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
       "  If increasing the limit yields no improvement it is advised to analyze \n",
       "  the integrand in order to determine the difficulties.  If the position of a \n",
       "  local difficulty can be determined (singularity, discontinuity) one will \n",
       "  probably gain from splitting up the interval and calling the integrator \n",
       "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
       "  return integrate.quad(lambda t: dC00dy_generating(t,ax,ay,r,dx_n,dy_n,method), 0, 1)[0]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ca182b99134b3699f513bf143cc782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:60: \n",
       "RuntimeWarning: overflow encountered in double_scalars\n",
       "  return sign*np.exp(-X-2*Y)/2/np.pi * integratedFactor\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:60: \n",
       "RuntimeWarning: overflow encountered in double_scalars\n",
       "  return sign*np.exp(-X-2*Y)/2/np.pi * integratedFactor\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:85: \n",
       "RuntimeWarning: invalid value encountered in double_scalars\n",
       "  return np.exp(-t/2*(azbar-dzbar)**2)*Bess2D(X,Y,0)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:85: \n",
       "RuntimeWarning: invalid value encountered in double_scalars\n",
       "  return np.exp(-t/2*(azbar-dzbar)**2)*Bess2D(X,Y,0)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:136: \n",
       "IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
       "  the requested tolerance from being achieved.  The error may be \n",
       "  underestimated.\n",
       "  return integrate.quad(lambda t: dC00dx_generating(t,ax,ay,r,dx_n,dy_n,method), 0, 1)[0]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:136: \n",
       "IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
       "  the requested tolerance from being achieved.  The error may be \n",
       "  underestimated.\n",
       "  return integrate.quad(lambda t: dC00dx_generating(t,ax,ay,r,dx_n,dy_n,method), 0, 1)[0]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:140: \n",
       "IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
       "  If increasing the limit yields no improvement it is advised to analyze \n",
       "  the integrand in order to determine the difficulties.  If the position of a \n",
       "  local difficulty can be determined (singularity, discontinuity) one will \n",
       "  probably gain from splitting up the interval and calling the integrator \n",
       "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
       "  return integrate.quad(lambda t: dC00dy_generating(t,ax,ay,r,dx_n,dy_n,method), 0, 1)[0]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/afs/cern.ch/work/c/cdroin/private/DA_study/master_study/analysis/backend_footprint_analysis/Detuning.py:140: \n",
       "IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
       "  If increasing the limit yields no improvement it is advised to analyze \n",
       "  the integrand in order to determine the difficulties.  If the position of a \n",
       "  local difficulty can be determined (singularity, discontinuity) one will \n",
       "  probably gain from splitting up the interval and calling the integrator \n",
       "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
       "  return integrate.quad(lambda t: dC00dy_generating(t,ax,ay,r,dx_n,dy_n,method), 0, 1)[0]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d4867e5dbd4d3da02bcb68d1e8ae02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'bb_ho.c1b1_00'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/afs/cern.ch/work/c/cdroin/private/DA_study/miniconda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/afs/cern.ch/work/c/cdroin/private/DA_study/miniconda/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/afs/cern.ch/work/c/cdroin/private/DA_study/miniconda/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bb_ho.c1b1_00'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 116\u001b[0m\n\u001b[1;32m    114\u001b[0m l_coordinates \u001b[39m=\u001b[39m []\n\u001b[1;32m    115\u001b[0m \u001b[39mfor\u001b[39;00m (twiss_b1, survey_b1, twiss_b2, survey_b2), b, bb \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(l_arr_cleaned, l_b, l_bb):\n\u001b[0;32m--> 116\u001b[0m     l_coordinates\u001b[39m.\u001b[39mappend(compute_footprint(twiss_b1, survey_b1, twiss_b2, survey_b2, b, bb))\n",
      "Cell \u001b[0;32mIn[5], line 100\u001b[0m, in \u001b[0;36mcompute_footprint\u001b[0;34m(twiss_b1, survey_b1, twiss_b2, survey_b2, b, bb)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39m# COMPUTING\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39m# =========================\u001b[39;00m\n\u001b[1;32m     99\u001b[0m s_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 100\u001b[0m (DQx_lr, DQy_lr), (DQx_ho, DQy_ho) \u001b[39m=\u001b[39m compute_lr_ho_footprint(coordinates)\n\u001b[1;32m    101\u001b[0m e_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    104\u001b[0m \u001b[39m# Saving data\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 77\u001b[0m, in \u001b[0;36mcompute_footprint.<locals>.compute_lr_ho_footprint\u001b[0;34m(coord)\u001b[0m\n\u001b[1;32m     74\u001b[0m     progress\u001b[39m.\u001b[39mupdate(task3, advance\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, refresh\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     76\u001b[0m \u001b[39m# Computing Head-on component (ex: bb_ho.c1b1_00):\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m main_ho \u001b[39m=\u001b[39m _IP\u001b[39m.\u001b[39;49mho\u001b[39m.\u001b[39;49mloc[\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbb_ho.c\u001b[39;49m\u001b[39m{\u001b[39;49;00m_IP\u001b[39m.\u001b[39;49mname[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m}\u001b[39;49;00m\u001b[39mb1_00\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     78\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m     79\u001b[0m _DQx, _DQy \u001b[39m=\u001b[39m dtune\u001b[39m.\u001b[39mDQx_DQy(\n\u001b[1;32m     80\u001b[0m     ax\u001b[39m=\u001b[39mcoord[\u001b[39m\"\u001b[39m\u001b[39mx_n\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     81\u001b[0m     ay\u001b[39m=\u001b[39mcoord[\u001b[39m\"\u001b[39m\u001b[39my_n\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     xi\u001b[39m=\u001b[39m_IP\u001b[39m.\u001b[39mb2\u001b[39m.\u001b[39mxi,\n\u001b[1;32m     88\u001b[0m )\n",
      "File \u001b[0;32m/afs/cern.ch/work/c/cdroin/private/DA_study/miniconda/lib/python3.10/site-packages/pandas/core/indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1070\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1072\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/afs/cern.ch/work/c/cdroin/private/DA_study/miniconda/lib/python3.10/site-packages/pandas/core/indexing.py:1312\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1312\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/afs/cern.ch/work/c/cdroin/private/DA_study/miniconda/lib/python3.10/site-packages/pandas/core/indexing.py:1260\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: \u001b[39mint\u001b[39m):\n\u001b[1;32m   1259\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1260\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/afs/cern.ch/work/c/cdroin/private/DA_study/miniconda/lib/python3.10/site-packages/pandas/core/generic.py:4056\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4054\u001b[0m             new_index \u001b[39m=\u001b[39m index[loc]\n\u001b[1;32m   4055\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4056\u001b[0m     loc \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   4058\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m   4059\u001b[0m         \u001b[39mif\u001b[39;00m loc\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mbool_:\n",
      "File \u001b[0;32m/afs/cern.ch/work/c/cdroin/private/DA_study/miniconda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bb_ho.c1b1_00'"
     ]
    }
   ],
   "source": [
    "def compute_footprint(twiss_b1, survey_b1, twiss_b2, survey_b2, b, bb):\n",
    "    # Define beams\n",
    "    B1 = inp.Beam(\n",
    "        \"b1\", twiss_b1, survey_b1, Nb=1.4e11, E=7.0e12, emittx_n=2.5e-6, emitty_n=2.5e-6, dp_p0=0\n",
    "    )\n",
    "\n",
    "    B2 = inp.Beam(\n",
    "        \"b2\", twiss_b2, survey_b2, Nb=1.4e11, E=7.0e12, emittx_n=2.5e-6, emitty_n=2.5e-6, dp_p0=0\n",
    "    )\n",
    "\n",
    "    IP1 = inp.InteractionPoint(\"ip1\", B1, B2)\n",
    "    IP5 = inp.InteractionPoint(\"ip5\", B1, B2)\n",
    "\n",
    "    # Generating Coord grid\n",
    "    # =========================================================\n",
    "    # coordinates = fp.generate_coordGrid([0.05,10],[0.01*np.pi/2,0.99*np.pi/2],labels = ['r_n','theta_n'],nPoints=500)\n",
    "    coordinates = fp.generate_coordGrid(\n",
    "        np.logspace(np.log10(0.5), np.log10(10), 10),\n",
    "        np.linspace(0.01 * np.pi / 2, 0.99 * np.pi / 2, 7),\n",
    "        labels=[\"r_n\", \"theta_n\"],\n",
    "    )\n",
    "\n",
    "    coordinates.insert(0, \"x_n\", coordinates[\"r_n\"] * np.cos(coordinates[\"theta_n\"]))\n",
    "    coordinates.insert(1, \"y_n\", coordinates[\"r_n\"] * np.sin(coordinates[\"theta_n\"]))\n",
    "\n",
    "    coordinates.insert(0, \"J_x\", (coordinates[\"x_n\"] ** 2) * B1.emittx / 2)\n",
    "    coordinates.insert(1, \"J_y\", (coordinates[\"y_n\"] ** 2) * B1.emitty / 2)\n",
    "\n",
    "    # coordinates.sort_values(by=['r_n'],inplace=True)\n",
    "    # =========================================================\n",
    "\n",
    "    def compute_lr_ho_footprint(coord):\n",
    "        DQx_oct, DQy_oct = np.zeros(len(coord[\"J_x\"])), np.zeros(len(coord[\"J_x\"]))\n",
    "        DQx_ho, DQy_ho = np.zeros(len(coord[\"J_x\"])), np.zeros(len(coord[\"J_x\"]))\n",
    "\n",
    "        with Progress(\n",
    "            \"{task.description}\",\n",
    "            SpinnerColumn(),\n",
    "            BarColumn(bar_width=40),\n",
    "            TextColumn(\"[progress.percentage]{task.percentage:>3.0f}%\"),\n",
    "            TimeElapsedColumn(),\n",
    "            TimeRemainingColumn(),\n",
    "        ) as progress:\n",
    "            task1 = progress.add_task(\"[red]Both IPs...\", total=2)\n",
    "            task2 = progress.add_task(\"[green]Each BBLR...\", total=len(IP1.lr))\n",
    "            task3 = progress.add_task(\"[green]Remaining time\", total=len(IP1.lr))\n",
    "\n",
    "            for _IP in [IP1, IP5]:\n",
    "                # Computing octupolar effect\n",
    "                # ------------------------------\n",
    "                # Iterating over LR only\n",
    "                progress.update(task2, completed=0, refresh=True)\n",
    "                progress.update(task3, completed=0, refresh=True)\n",
    "                for index, _bb in _IP.lr.iterrows():\n",
    "                    _DQx, _DQy = dtune.DQx_DQy(\n",
    "                        ax=coord[\"x_n\"],\n",
    "                        ay=coord[\"y_n\"],\n",
    "                        r=_bb[\"r\"],\n",
    "                        dx_n=_bb[\"dx_n\"],\n",
    "                        dy_n=_bb[\"dy_n\"],\n",
    "                        A_w_s=_bb[\"A_w_s\"],\n",
    "                        B_w_s=_bb[\"B_w_s\"],\n",
    "                        xi=_IP.b2.xi,\n",
    "                    )\n",
    "\n",
    "                    DQx_oct += _DQx\n",
    "                    DQy_oct += _DQy\n",
    "\n",
    "                    progress.reset(task2, completed=progress.tasks[task2].completed)\n",
    "                    progress.update(task2, advance=1, refresh=True)\n",
    "                    progress.update(task3, advance=1, refresh=True)\n",
    "\n",
    "                # Computing Head-on component (ex: bb_ho.c1b1_00):\n",
    "                main_ho = _IP.ho.loc[f\"bb_ho.c{_IP.name[-1]}b1_00\"]\n",
    "                # ------------------------------\n",
    "                _DQx, _DQy = dtune.DQx_DQy(\n",
    "                    ax=coord[\"x_n\"],\n",
    "                    ay=coord[\"y_n\"],\n",
    "                    r=main_ho[\"r\"],\n",
    "                    dx_n=main_ho[\"dx_n\"],\n",
    "                    dy_n=main_ho[\"dy_n\"],\n",
    "                    A_w_s=main_ho[\"A_w_s\"],\n",
    "                    B_w_s=main_ho[\"B_w_s\"],\n",
    "                    xi=_IP.b2.xi,\n",
    "                )\n",
    "                DQx_ho += _DQx\n",
    "                DQy_ho += _DQy\n",
    "\n",
    "                progress.update(task1, advance=1, refresh=True)\n",
    "\n",
    "        return (DQx_oct, DQy_oct), (DQx_ho, DQy_ho)\n",
    "\n",
    "    # COMPUTING\n",
    "    # =========================\n",
    "    s_time = time.time()\n",
    "    (DQx_lr, DQy_lr), (DQx_ho, DQy_ho) = compute_lr_ho_footprint(coordinates)\n",
    "    e_time = time.time()\n",
    "\n",
    "    # Saving data\n",
    "    coordinates.insert(1, \"DQx_lr\", DQx_lr)\n",
    "    coordinates.insert(2, \"DQy_lr\", DQy_lr)\n",
    "    coordinates.insert(3, \"DQx_ho\", DQx_ho)\n",
    "    coordinates.insert(4, \"DQy_ho\", DQy_ho)\n",
    "\n",
    "    coordinates.to_pickle(f\"data/Bessel_footprint_\" + str(b) + \"_\" + str(bb) + \".pkl\")\n",
    "\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "l_coordinates = []\n",
    "for (twiss_b1, survey_b1, twiss_b2, survey_b2), b, bb in zip(l_arr_cleaned, l_b, l_bb):\n",
    "    l_coordinates.append(compute_footprint(twiss_b1, survey_b1, twiss_b2, survey_b2, b, bb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_footprint(coordinates, b, bb):\n",
    "    # PLOTTING\n",
    "    # ================================================================\n",
    "    Qx_0, Qy_0 = 0.316, 0.321\n",
    "\n",
    "    cmap = \"viridis\"\n",
    "    # fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    # fig.suptitle(f'Analytical footprint for WP [62.316, 60.321], chroma 15, bunch {b}, beam-beam: {bb}\\n')\n",
    "\n",
    "    # # Plotting coordinates\n",
    "    # # -----------------------\n",
    "    # plt.sca(axes[0, 0])\n",
    "    # axes[0, 0].set_title(\"Coordinates\")\n",
    "    # plt.scatter(\n",
    "    #     coordinates[\"x_n\"],\n",
    "    #     coordinates[\"y_n\"],\n",
    "    #     s=5,\n",
    "    #     c=coordinates[\"r_n\"],\n",
    "    #     alpha=0.8,\n",
    "    #     norm=BoundaryNorm(boundaries=np.linspace(0, 10, 11), ncolors=int(0.9 * 256)),\n",
    "    # )\n",
    "    # plt.xlabel(r\"$x_n$\", fontsize=16)\n",
    "    # plt.ylabel(r\"$y_n$\", fontsize=16)\n",
    "    # plt.axis(\"equal\")\n",
    "    # cbar = plt.colorbar()\n",
    "    # plt.set_cmap(cmap)\n",
    "    # cbar.ax.set_ylim([0, np.max(coordinates[\"r_n\"])])\n",
    "    # cbar.ax.set_ylabel(r\"$\\sqrt{(2J_x + 2J_y)/\\varepsilon}$ [$\\sigma$]\", fontsize=12)\n",
    "\n",
    "    # # Plotting LR only\n",
    "    # # -----------------------\n",
    "    # plt.sca(axes[0, 1])\n",
    "    # axes[0, 1].set_title(\"LR only\")\n",
    "    # BP.plotWorkingDiagram(\n",
    "    #     order=12,\n",
    "    #     QxRange=np.array([0.25, 0.35]),\n",
    "    #     QyRange=np.array([0.25, 0.35]),\n",
    "    #     alpha=0.2,\n",
    "    #     zorder=-1000,\n",
    "    # )\n",
    "    # plt.plot([Qx_0], [Qy_0], \"P\", markersize=5, color=\"C3\", alpha=0.5, label=\"Unperturbed W.P.\")\n",
    "\n",
    "    # plt.scatter(\n",
    "    #     Qx_0 + coordinates[\"DQx_lr\"],\n",
    "    #     Qy_0 + coordinates[\"DQy_lr\"],\n",
    "    #     s=5,\n",
    "    #     c=coordinates[\"r_n\"],\n",
    "    #     alpha=0.8,\n",
    "    #     norm=BoundaryNorm(boundaries=np.linspace(0, 10, 11), ncolors=int(0.9 * 256)),\n",
    "    # )\n",
    "    # plt.xlabel(r\"$Q_x$\", fontsize=16)\n",
    "    # plt.ylabel(r\"$Q_y$\", fontsize=16)\n",
    "    # plt.axis(\"equal\")\n",
    "    # window = 0.02\n",
    "    # plt.xlim([Qx_0 - window, Qx_0 + window])\n",
    "    # plt.ylim([Qy_0 - window, Qy_0 + window])\n",
    "    # cbar = plt.colorbar()\n",
    "    # plt.set_cmap(cmap)\n",
    "    # cbar.ax.set_ylim([0, np.max(coordinates[\"r_n\"])])\n",
    "    # cbar.ax.set_ylabel(r\"$\\sqrt{(2J_x + 2J_y)/\\varepsilon}$ [$\\sigma$]\", fontsize=12)\n",
    "\n",
    "    # # Plotting head-on only\n",
    "    # # -----------------------\n",
    "    # plt.sca(axes[1, 0])\n",
    "    # axes[1, 0].set_title(\"Head-on only\")\n",
    "    # BP.plotWorkingDiagram(\n",
    "    #     order=12,\n",
    "    #     QxRange=np.array([0.25, 0.35]),\n",
    "    #     QyRange=np.array([0.25, 0.35]),\n",
    "    #     alpha=0.2,\n",
    "    #     zorder=-1000,\n",
    "    # )\n",
    "    # plt.plot([Qx_0], [Qy_0], \"P\", markersize=5, color=\"C3\", alpha=0.5, label=\"Unperturbed W.P.\")\n",
    "\n",
    "    # plt.scatter(\n",
    "    #     Qx_0 + coordinates[\"DQx_ho\"],\n",
    "    #     Qy_0 + coordinates[\"DQy_ho\"],\n",
    "    #     s=5,\n",
    "    #     c=coordinates[\"r_n\"],\n",
    "    #     alpha=0.8,\n",
    "    #     norm=BoundaryNorm(boundaries=np.linspace(0, 10, 11), ncolors=int(0.9 * 256)),\n",
    "    # )\n",
    "    # plt.xlabel(r\"$Q_x$\", fontsize=16)\n",
    "    # plt.ylabel(r\"$Q_y$\", fontsize=16)\n",
    "    # plt.axis(\"equal\")\n",
    "    # window = 0.02\n",
    "    # plt.xlim([Qx_0 - window, Qx_0 + window])\n",
    "    # plt.ylim([Qy_0 - window, Qy_0 + window])\n",
    "    # cbar = plt.colorbar()\n",
    "    # plt.set_cmap(cmap)\n",
    "    # cbar.ax.set_ylim([0, np.max(coordinates[\"r_n\"])])\n",
    "    # cbar.ax.set_ylabel(r\"$\\sqrt{(2J_x + 2J_y)/\\varepsilon}$ [$\\sigma$]\", fontsize=12)\n",
    "\n",
    "    # Plotting all together\n",
    "    # -----------------------\n",
    "    # plt.sca(axes[0, 0])\n",
    "    # axes[1, 1].set_title(\"HO + LR\")\n",
    "    BP.plotWorkingDiagram(\n",
    "        order=12,\n",
    "        QxRange=np.array([0.25, 0.35]),\n",
    "        QyRange=np.array([0.25, 0.35]),\n",
    "        alpha=0.2,\n",
    "        zorder=-1000,\n",
    "    )\n",
    "    #plt.plot([Qx_0], [Qy_0], \"P\", markersize=5, color=\"C3\", alpha=0.5, label=\"Unperturbed W.P.\")\n",
    "\n",
    "    scatter = plt.scatter(\n",
    "        Qx_0 + coordinates[\"DQx_lr\"] + coordinates[\"DQx_ho\"],\n",
    "        Qy_0 + coordinates[\"DQy_lr\"] + coordinates[\"DQy_ho\"],\n",
    "        s=5,\n",
    "        c=coordinates[\"r_n\"],\n",
    "        alpha=0.8,\n",
    "        norm=BoundaryNorm(boundaries=np.linspace(0, 10, 11), ncolors=int(0.9 * 256)),\n",
    "    )\n",
    "    plt.xlabel(r\"$Q_x$\", fontsize=16)\n",
    "    plt.ylabel(r\"$Q_y$\", fontsize=16)\n",
    "    plt.axis(\"equal\")\n",
    "    window = 0.02\n",
    "    plt.xlim([Qx_0 - window, Qx_0 + window])\n",
    "    plt.ylim([Qy_0 - window, Qy_0 + window])\n",
    "    cbar = plt.colorbar()\n",
    "    plt.set_cmap(cmap)\n",
    "    cbar.ax.set_ylim([0, np.max(coordinates[\"r_n\"])])\n",
    "    cbar.ax.set_ylabel(r\"$\\sqrt{(2J_x + 2J_y)/\\varepsilon}$ [$\\sigma$]\", fontsize=12)\n",
    "\n",
    "    plt.title(f'Analytical footprint for WP [62.316, 60.321], bunch {b}, beam-beam: {bb}\\n', fontsize = 10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"data/footprint_\" + str(b) + \"_\" + str(bb) + \".pdf\", format=\"pdf\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Load coordinates from pickle\n",
    "for b, bb in zip(l_b, l_bb):\n",
    "    coordinates = pd.read_pickle(f\"data/Bessel_footprint_\" + str(b) + \"_\" + str(bb) + \".pkl\")\n",
    "    plot_footprint(coordinates, b, bb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "258ed27130092d1611e438a5ae26a3133782840bad2ac649c8a295d1052b554d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
